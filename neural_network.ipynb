{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 20:21:09.333970: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T18:49:20.490091Z",
     "end_time": "2023-04-07T18:49:27.618451Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 20:22:40.339984: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 1s 2ms/step - loss: 0.6751 - accuracy: 0.5589 - val_loss: 0.6261 - val_accuracy: 0.6478\n",
      "Epoch 2/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.6156 - val_loss: 0.6111 - val_accuracy: 0.6704\n",
      "Epoch 3/25\n",
      "266/266 [==============================] - 1s 2ms/step - loss: 0.6286 - accuracy: 0.6423 - val_loss: 0.6019 - val_accuracy: 0.6911\n",
      "Epoch 4/25\n",
      "266/266 [==============================] - 1s 2ms/step - loss: 0.6179 - accuracy: 0.6502 - val_loss: 0.5962 - val_accuracy: 0.6977\n",
      "Epoch 5/25\n",
      "266/266 [==============================] - 1s 2ms/step - loss: 0.6175 - accuracy: 0.6647 - val_loss: 0.5946 - val_accuracy: 0.7001\n",
      "Epoch 6/25\n",
      "266/266 [==============================] - 1s 2ms/step - loss: 0.6122 - accuracy: 0.6786 - val_loss: 0.5891 - val_accuracy: 0.6996\n",
      "Epoch 7/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.6824 - val_loss: 0.5849 - val_accuracy: 0.7029\n",
      "Epoch 8/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.6859 - val_loss: 0.5846 - val_accuracy: 0.7024\n",
      "Epoch 9/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.6854 - val_loss: 0.5852 - val_accuracy: 0.7034\n",
      "Epoch 10/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6896 - val_loss: 0.5815 - val_accuracy: 0.7062\n",
      "Epoch 11/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.6927 - val_loss: 0.5801 - val_accuracy: 0.7062\n",
      "Epoch 12/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6930 - val_loss: 0.5789 - val_accuracy: 0.7053\n",
      "Epoch 13/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.6895 - val_loss: 0.5778 - val_accuracy: 0.7076\n",
      "Epoch 14/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.6945 - val_loss: 0.5779 - val_accuracy: 0.7057\n",
      "Epoch 15/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.6889 - val_loss: 0.5776 - val_accuracy: 0.7020\n",
      "Epoch 16/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6905 - val_loss: 0.5780 - val_accuracy: 0.7048\n",
      "Epoch 17/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.6989 - val_loss: 0.5768 - val_accuracy: 0.7095\n",
      "Epoch 18/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.6972 - val_loss: 0.5777 - val_accuracy: 0.7072\n",
      "Epoch 19/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.6965 - val_loss: 0.5751 - val_accuracy: 0.7086\n",
      "Epoch 20/25\n",
      "266/266 [==============================] - 1s 2ms/step - loss: 0.5868 - accuracy: 0.6941 - val_loss: 0.5750 - val_accuracy: 0.7057\n",
      "Epoch 21/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.6959 - val_loss: 0.5747 - val_accuracy: 0.7081\n",
      "Epoch 22/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.6927 - val_loss: 0.5743 - val_accuracy: 0.7048\n",
      "Epoch 23/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.7000 - val_loss: 0.5774 - val_accuracy: 0.7081\n",
      "Epoch 24/25\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.6995 - val_loss: 0.5734 - val_accuracy: 0.7081\n",
      "Epoch 25/25\n",
      "266/266 [==============================] - 1s 2ms/step - loss: 0.5804 - accuracy: 0.6943 - val_loss: 0.5753 - val_accuracy: 0.7081\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "Accuracy: 69.30%\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('balanced_credit.csv')\n",
    "\n",
    "X = data.drop('default', axis=1).values\n",
    "y = data['default'].values\n",
    "\n",
    "# SPlit data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build model structure\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile and fit model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=25, batch_size=32, verbose=1)\n",
    "\n",
    "# make predictions and output metrics\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T18:49:27.619279Z",
     "end_time": "2023-04-07T18:49:41.168746Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 8s 26ms/step - loss: 0.6362 - accuracy: 0.6357 - val_loss: 0.6055 - val_accuracy: 0.6780\n",
      "Epoch 2/50\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.6025 - accuracy: 0.6822 - val_loss: 0.5931 - val_accuracy: 0.6907\n",
      "Epoch 3/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5919 - accuracy: 0.6919 - val_loss: 0.5849 - val_accuracy: 0.6982\n",
      "Epoch 4/50\n",
      "266/266 [==============================] - 7s 26ms/step - loss: 0.5848 - accuracy: 0.6974 - val_loss: 0.5829 - val_accuracy: 0.6944\n",
      "Epoch 5/50\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.5803 - accuracy: 0.6963 - val_loss: 0.5797 - val_accuracy: 0.6977\n",
      "Epoch 6/50\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.5763 - accuracy: 0.7013 - val_loss: 0.5812 - val_accuracy: 0.6911\n",
      "Epoch 7/50\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.5735 - accuracy: 0.7005 - val_loss: 0.5779 - val_accuracy: 0.7006\n",
      "Epoch 8/50\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.5704 - accuracy: 0.7027 - val_loss: 0.5789 - val_accuracy: 0.6982\n",
      "Epoch 9/50\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.5689 - accuracy: 0.7025 - val_loss: 0.5778 - val_accuracy: 0.7001\n",
      "Epoch 10/50\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.5666 - accuracy: 0.7042 - val_loss: 0.5767 - val_accuracy: 0.6977\n",
      "Epoch 11/50\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.5646 - accuracy: 0.7060 - val_loss: 0.5781 - val_accuracy: 0.7034\n",
      "Epoch 12/50\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.5635 - accuracy: 0.7086 - val_loss: 0.5791 - val_accuracy: 0.6911\n",
      "Epoch 13/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5621 - accuracy: 0.7089 - val_loss: 0.5776 - val_accuracy: 0.6992\n",
      "Epoch 14/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5613 - accuracy: 0.7088 - val_loss: 0.5759 - val_accuracy: 0.6949\n",
      "Epoch 15/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5595 - accuracy: 0.7131 - val_loss: 0.5777 - val_accuracy: 0.6940\n",
      "Epoch 16/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5585 - accuracy: 0.7113 - val_loss: 0.5751 - val_accuracy: 0.6968\n",
      "Epoch 17/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5574 - accuracy: 0.7121 - val_loss: 0.5765 - val_accuracy: 0.6963\n",
      "Epoch 18/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5562 - accuracy: 0.7134 - val_loss: 0.5743 - val_accuracy: 0.6977\n",
      "Epoch 19/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5547 - accuracy: 0.7142 - val_loss: 0.5765 - val_accuracy: 0.6897\n",
      "Epoch 20/50\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.5542 - accuracy: 0.7141 - val_loss: 0.5835 - val_accuracy: 0.6798\n",
      "Epoch 21/50\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.5543 - accuracy: 0.7158 - val_loss: 0.5777 - val_accuracy: 0.6916\n",
      "Epoch 22/50\n",
      "266/266 [==============================] - 7s 27ms/step - loss: 0.5529 - accuracy: 0.7152 - val_loss: 0.5763 - val_accuracy: 0.6935\n",
      "Epoch 23/50\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 0.5519 - accuracy: 0.7138 - val_loss: 0.5765 - val_accuracy: 0.6926\n",
      "Epoch 24/50\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 0.5509 - accuracy: 0.7155 - val_loss: 0.5774 - val_accuracy: 0.6987\n",
      "Epoch 25/50\n",
      "266/266 [==============================] - 7s 26ms/step - loss: 0.5499 - accuracy: 0.7182 - val_loss: 0.5777 - val_accuracy: 0.6935\n",
      "Epoch 26/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5494 - accuracy: 0.7162 - val_loss: 0.5762 - val_accuracy: 0.6935\n",
      "Epoch 27/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5486 - accuracy: 0.7192 - val_loss: 0.5757 - val_accuracy: 0.6959\n",
      "Epoch 28/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5473 - accuracy: 0.7197 - val_loss: 0.5761 - val_accuracy: 0.6954\n",
      "Epoch 29/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5468 - accuracy: 0.7195 - val_loss: 0.5747 - val_accuracy: 0.6949\n",
      "Epoch 30/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5466 - accuracy: 0.7227 - val_loss: 0.5784 - val_accuracy: 0.7006\n",
      "Epoch 31/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5455 - accuracy: 0.7200 - val_loss: 0.5769 - val_accuracy: 0.6982\n",
      "Epoch 32/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5442 - accuracy: 0.7212 - val_loss: 0.5850 - val_accuracy: 0.6916\n",
      "Epoch 33/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5440 - accuracy: 0.7195 - val_loss: 0.5759 - val_accuracy: 0.6987\n",
      "Epoch 34/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5433 - accuracy: 0.7231 - val_loss: 0.5782 - val_accuracy: 0.6944\n",
      "Epoch 35/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5432 - accuracy: 0.7238 - val_loss: 0.5792 - val_accuracy: 0.6954\n",
      "Epoch 36/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5424 - accuracy: 0.7207 - val_loss: 0.5780 - val_accuracy: 0.6973\n",
      "Epoch 37/50\n",
      "266/266 [==============================] - 8s 28ms/step - loss: 0.5415 - accuracy: 0.7240 - val_loss: 0.5794 - val_accuracy: 0.6968\n",
      "Epoch 38/50\n",
      "266/266 [==============================] - 7s 27ms/step - loss: 0.5403 - accuracy: 0.7234 - val_loss: 0.5799 - val_accuracy: 0.6926\n",
      "Epoch 39/50\n",
      "266/266 [==============================] - 7s 26ms/step - loss: 0.5401 - accuracy: 0.7232 - val_loss: 0.5793 - val_accuracy: 0.6916\n",
      "Epoch 40/50\n",
      "266/266 [==============================] - 7s 25ms/step - loss: 0.5391 - accuracy: 0.7244 - val_loss: 0.5805 - val_accuracy: 0.6954\n",
      "Epoch 41/50\n",
      "266/266 [==============================] - 7s 26ms/step - loss: 0.5388 - accuracy: 0.7213 - val_loss: 0.5785 - val_accuracy: 0.6973\n",
      "Epoch 42/50\n",
      "266/266 [==============================] - 7s 27ms/step - loss: 0.5382 - accuracy: 0.7266 - val_loss: 0.5804 - val_accuracy: 0.6926\n",
      "Epoch 43/50\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.5373 - accuracy: 0.7247 - val_loss: 0.5820 - val_accuracy: 0.6935\n",
      "Epoch 44/50\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.5368 - accuracy: 0.7262 - val_loss: 0.5804 - val_accuracy: 0.6935\n",
      "Epoch 45/50\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.5365 - accuracy: 0.7277 - val_loss: 0.5797 - val_accuracy: 0.6916\n",
      "Epoch 46/50\n",
      "266/266 [==============================] - 7s 27ms/step - loss: 0.5364 - accuracy: 0.7252 - val_loss: 0.5813 - val_accuracy: 0.6921\n",
      "Epoch 47/50\n",
      "266/266 [==============================] - 7s 26ms/step - loss: 0.5351 - accuracy: 0.7261 - val_loss: 0.5833 - val_accuracy: 0.6949\n",
      "Epoch 48/50\n",
      "266/266 [==============================] - 7s 27ms/step - loss: 0.5354 - accuracy: 0.7270 - val_loss: 0.5834 - val_accuracy: 0.6940\n",
      "Epoch 49/50\n",
      "266/266 [==============================] - 7s 26ms/step - loss: 0.5344 - accuracy: 0.7295 - val_loss: 0.5808 - val_accuracy: 0.6977\n",
      "Epoch 50/50\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.5342 - accuracy: 0.7281 - val_loss: 0.5848 - val_accuracy: 0.6973\n",
      "67/83 [=======================>......] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 20:28:15.630819: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step\n",
      "Accuracy: 70.70%\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('balanced_credit.csv')\n",
    "\n",
    "# One-hot encoding\n",
    "data['EDUCATION'] = data['EDUCATION'].map(lambda x: 0 if x in [1, 2] else 1)\n",
    "data['MARRIAGE'] = data['MARRIAGE'].map(lambda x: 0 if x == 1 else 1)\n",
    "data['PAY_6'] = data['PAY_6'].map(lambda x: 0 if x in [-1, 1, 2] else 1)\n",
    "\n",
    "X = data.drop('default', axis=1).values\n",
    "y = data['default'].values\n",
    "\n",
    "# Convert binary labels to categorical labels with two classes\n",
    "y = np.array([[1, 0] if label == 0 else [0, 1] for label in y])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential([\n",
    "    Dense(25, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "y_test_labels = y_test.argmax(axis=1)\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T18:49:41.175187Z",
     "end_time": "2023-04-07T18:49:54.489338Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6960 with learning_rate=0.001, neurons=16, dropout_rate=None, epochs=25\n",
      "Elapsed time: 0.17 minutes\n",
      "Accuracy: 0.6960 with learning_rate=0.001, neurons=16, dropout_rate=None, epochs=50\n",
      "Elapsed time: 0.37 minutes\n",
      "Accuracy: 0.6991 with learning_rate=0.001, neurons=16, dropout_rate=0.2, epochs=25\n",
      "Elapsed time: 0.17 minutes\n",
      "Accuracy: 0.7024 with learning_rate=0.001, neurons=16, dropout_rate=0.2, epochs=50\n",
      "Elapsed time: 0.30 minutes\n",
      "Accuracy: 0.6874 with learning_rate=0.001, neurons=32, dropout_rate=None, epochs=25\n",
      "Elapsed time: 0.20 minutes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 67\u001B[0m\n\u001B[1;32m     63\u001B[0m learning_rate, neuron, dropout_rate, epoch \u001B[38;5;241m=\u001B[39m combo\n\u001B[1;32m     64\u001B[0m model \u001B[38;5;241m=\u001B[39m KerasClassifier(model\u001B[38;5;241m=\u001B[39mcreate_model, epochs\u001B[38;5;241m=\u001B[39mepoch, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m     65\u001B[0m                         learning_rate\u001B[38;5;241m=\u001B[39mlearning_rate, neurons\u001B[38;5;241m=\u001B[39mneuron, dropout_rate\u001B[38;5;241m=\u001B[39mdropout_rate)\n\u001B[0;32m---> 67\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     68\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mscore(X_test, y_test)\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccuracy\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m with learning_rate=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlearning_rate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, neurons=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mneuron\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, dropout_rate=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdropout_rate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, epochs=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.9/site-packages/scikeras/wrappers.py:1494\u001B[0m, in \u001B[0;36mKerasClassifier.fit\u001B[0;34m(self, X, y, sample_weight, **kwargs)\u001B[0m\n\u001B[1;32m   1492\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m sample_weight\n\u001B[1;32m   1493\u001B[0m     sample_weight \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m compute_sample_weight(class_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclass_weight, y\u001B[38;5;241m=\u001B[39my)\n\u001B[0;32m-> 1494\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1495\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.9/site-packages/scikeras/wrappers.py:762\u001B[0m, in \u001B[0;36mBaseWrapper.fit\u001B[0;34m(self, X, y, sample_weight, **kwargs)\u001B[0m\n\u001B[1;32m    757\u001B[0m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepochs\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mget(\n\u001B[1;32m    758\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepochs\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit__epochs\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepochs)\n\u001B[1;32m    759\u001B[0m )\n\u001B[1;32m    760\u001B[0m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minitial_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minitial_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m--> 762\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    763\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    764\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    765\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    766\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwarm_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwarm_start\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    767\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    768\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    770\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.9/site-packages/scikeras/wrappers.py:931\u001B[0m, in \u001B[0;36mBaseWrapper._fit\u001B[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001B[0m\n\u001B[1;32m    927\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_encoder_\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[1;32m    929\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_model_compatibility(y)\n\u001B[0;32m--> 931\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_keras_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    932\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    933\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    934\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    935\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwarm_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwarm_start\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    936\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    937\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    938\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    939\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.9/site-packages/scikeras/wrappers.py:526\u001B[0m, in \u001B[0;36mBaseWrapper._fit_keras_model\u001B[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001B[0m\n\u001B[1;32m    524\u001B[0m         hist \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_\u001B[38;5;241m.\u001B[39mfit(x\u001B[38;5;241m=\u001B[39mX, y\u001B[38;5;241m=\u001B[39my, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_args)\n\u001B[1;32m    525\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 526\u001B[0m     hist \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m warm_start \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhistory_\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m initial_epoch \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    529\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhistory_ \u001B[38;5;241m=\u001B[39m defaultdict(\u001B[38;5;28mlist\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.9/site-packages/keras/engine/training.py:1409\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1402\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1403\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1404\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   1405\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   1406\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1407\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1408\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1409\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1410\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1411\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2450\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m   2451\u001B[0m   (graph_function,\n\u001B[1;32m   2452\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2453\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2454\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1856\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1857\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1858\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1859\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1860\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1861\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1862\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1863\u001B[0m     args,\n\u001B[1;32m   1864\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1865\u001B[0m     executing_eagerly)\n\u001B[1;32m   1866\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    495\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    496\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 497\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    503\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    504\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    505\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    506\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    509\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    510\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from tensorflow.keras import backend\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import time\n",
    "\n",
    "data = pd.read_csv('balanced_credit.csv')\n",
    "\n",
    "X = data.drop('default', axis=1).values\n",
    "y = data['default'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "def create_model(learning_rate=0.001, neurons=64, dropout_rate=0.2):\n",
    "    backend.clear_session()\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    if dropout_rate is None:\n",
    "        model = Sequential([\n",
    "            Dense(neurons, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "            Dense(neurons // 2, activation='relu'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "    else:\n",
    "        if neurons < 128:\n",
    "            model = Sequential([\n",
    "                Dense(neurons, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "                Dropout(dropout_rate),\n",
    "                Dense(neurons // 2, activation='relu'),\n",
    "                Dropout(dropout_rate),\n",
    "                Dense(1, activation='sigmoid')\n",
    "            ])\n",
    "        else:\n",
    "            model = Sequential([\n",
    "                Dense(neurons, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "                Dropout(dropout_rate * 2),\n",
    "                Dense(neurons // 2, activation='relu'),\n",
    "                Dropout(dropout_rate * 2),\n",
    "                Dense(neurons // 4, activation='relu'),\n",
    "                Dropout(dropout_rate),\n",
    "                Dense(1, activation='sigmoid')\n",
    "            ])\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Hyperparameter grid\n",
    "learning_rates = [0.001]\n",
    "neurons = [16, 32, 64, 128]\n",
    "dropout_rates = [None, 0.2]\n",
    "epochs = [25, 50]\n",
    "\n",
    "combinations = list(itertools.product(learning_rates, neurons, dropout_rates, epochs))\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "for combo in combinations:\n",
    "    start_time = time.time()\n",
    "\n",
    "    learning_rate, neuron, dropout_rate, epoch = combo\n",
    "    model = KerasClassifier(model=create_model, epochs=epoch, batch_size=32, verbose=0,\n",
    "                            learning_rate=learning_rate, neurons=neuron, dropout_rate=dropout_rate)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f\"Accuracy: {accuracy:.4f} with learning_rate={learning_rate}, neurons={neuron}, dropout_rate={dropout_rate}, epochs={epoch}\")\n",
    "\n",
    "    elapsed_time = (time.time() - start_time) / 60\n",
    "    print(f\"Elapsed time: {elapsed_time:.2f} minutes\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = combo\n",
    "\n",
    "print(f\"Best accuracy: {best_accuracy:.4f} with learning_rate={best_params[0]}, neurons={best_params[1]}, dropout_rate={best_params[2]}, epochs={best_params[3]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
